{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8nRbt/obiW1hk0XtK21KI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioGzSl/word2vec/blob/main/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWgEs7MgHJRo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "def preprocess(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "dataset_wikipedia = load_dataset(\"wikipedia\", \"20220301.en\", split='train')\n",
        "\n",
        "N = 100\n",
        "text = []\n",
        "for i in range(N):\n",
        "    article = dataset_wikipedia[i]['text']\n",
        "    text.extend(preprocess(article))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def create_vocabulary(text):\n",
        "    word_counts = Counter(text)\n",
        "    vocabulary = {word: idx for idx, word in enumerate(word_counts)}\n",
        "    return vocabulary, word_counts"
      ],
      "metadata": {
        "id": "DnCcOXxrH7F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGramDataset(Dataset):\n",
        "    def __init__(self, text, window_size=2):\n",
        "        self.text = text\n",
        "        self.window_size = window_size\n",
        "        self.vocabulary, self.word_counts = create_vocabulary(text)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      target_word = self.text[idx]\n",
        "      target_idx = self.vocabulary[target_word]\n",
        "\n",
        "      start = idx - self.window_size\n",
        "      end = idx + self.window_size + 1\n",
        "\n",
        "      context_indices = []\n",
        "      for i in range(start, end):\n",
        "          if i != idx and 0 <= i < len(self.text):\n",
        "              context_indices.append(self.vocabulary[self.text[i]])\n",
        "          elif i != idx:\n",
        "              context_indices.append(0)\n",
        "\n",
        "      context_tensor = torch.tensor(context_indices, dtype=torch.long)\n",
        "      target_tensor = torch.tensor(target_idx, dtype=torch.long)\n",
        "\n",
        "      return context_tensor, target_tensor\n",
        "\n",
        "class SkipGramModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(SkipGramModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.output_layer = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, target_idxs):\n",
        "        target_embeds = self.embeddings(target_idxs)\n",
        "        out = self.output_layer(target_embeds)\n",
        "        log_probs = torch.log_softmax(out, dim=1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "GOWX9eJCIPBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SkipGramDataset(text)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "vocab_size = len(dataset.vocabulary)\n",
        "embedding_dim = 128\n",
        "\n",
        "model = SkipGramModel(vocab_size, embedding_dim).to(device)"
      ],
      "metadata": {
        "id": "EQm9Xb9Oikkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for context, target in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
        "        target, context = target.to(device), context.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        log_probs = model(target)\n",
        "\n",
        "        log_probs = log_probs.unsqueeze(1).repeat(1, context.size(1), 1)\n",
        "        log_probs = log_probs.view(-1, log_probs.size(-1))\n",
        "\n",
        "        context = context.view(-1)\n",
        "        loss = loss_function(log_probs, context)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch}, Total loss: {total_loss}\")\n",
        "\n",
        "\n",
        "torch.save(model.embeddings.state_dict(), 'word_embeddings.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yo-96gMJW4E",
        "outputId": "37ea571f-3ba5-4bc7-ae70-7d57b291c26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 3810/3810 [00:50<00:00, 75.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Total loss: 41500.32925224304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 3810/3810 [00:50<00:00, 75.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Total loss: 39893.88434123993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 3810/3810 [00:50<00:00, 75.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Total loss: 38725.03659439087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 3810/3810 [00:50<00:00, 75.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Total loss: 37820.6716632843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 3810/3810 [00:50<00:00, 74.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Total loss: 37117.140500068665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 3810/3810 [00:50<00:00, 75.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Total loss: 36586.55619430542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 3810/3810 [00:50<00:00, 75.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Total loss: 36170.13304901123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 3810/3810 [00:50<00:00, 75.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Total loss: 35827.666774749756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 3810/3810 [00:50<00:00, 75.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Total loss: 35544.81055355072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 3810/3810 [00:50<00:00, 75.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Total loss: 35309.880621910095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_inverse_vocabulary(vocabulary):\n",
        "    inverse_vocabulary = {idx: word for word, idx in vocabulary.items()}\n",
        "    return inverse_vocabulary\n",
        "\n",
        "vocabulary, inverse_vocabulary = dataset.vocabulary, create_inverse_vocabulary(dataset.vocabulary)\n",
        "\n",
        "def evaluate_word(model, word, vocabulary, inverse_vocabulary, device='cpu'):\n",
        "    model.to(device).eval()\n",
        "\n",
        "    if word in vocabulary:\n",
        "        word_idx = torch.tensor([vocabulary[word]], dtype=torch.long).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            log_probs = model(word_idx)\n",
        "\n",
        "        probs = torch.exp(log_probs).squeeze(0)\n",
        "\n",
        "        topk_values, topk_indices = probs.topk(10, largest=True, sorted=True)\n",
        "\n",
        "        top_words = [inverse_vocabulary[idx.item()] for idx in topk_indices]\n",
        "\n",
        "        return top_words, topk_values\n",
        "    else:\n",
        "        return f\"La palabra '{word}' no se encontró en el vocabulario.\", None\n",
        "\n"
      ],
      "metadata": {
        "id": "93EUX356KPoo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_test = \"king\"\n",
        "top_words, top_values = evaluate_word(model, word_to_test, vocabulary, inverse_vocabulary, device='cpu')\n",
        "print(f\"Las palabras más probables para '{word_to_test}' son:\")\n",
        "for word, value in zip(top_words, top_values):\n",
        "    print(f\"{word}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "Ty8MhRM7fmF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9383748f-95c5-4326-98eb-751fe0519a90"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Las palabras más probables para 'king' son:\n",
            "the: 0.1016\n",
            "and: 0.0320\n",
            "of: 0.0295\n",
            "in: 0.0140\n",
            "to: 0.0068\n",
            "a: 0.0018\n",
            "that: 0.0002\n",
            "by: 0.0002\n",
            "hectocotyl: 0.0001\n",
            "vector: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VU8A630fw0a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}